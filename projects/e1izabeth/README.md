Данный проект является результатом выполнения практических заданий курса ИТМО по автоматической обработке текстов (2022).

## Структура проекта

* `assets` - вспомогательные и конфигурационные файлы, не являющиеся исходным кодом.
    * `raw-dataset` - директория с исходными датасетами (добавлена в .gitignore).
    * `test` - генерируемая модулем токенизации директория.
    * `train` - генерируемая модулем токенизации директория c .
* `source` - исходный код.
    * `tokenizer` - модуль, реализующий функциональность токенизации.
    * `typos` - модуль исправления опечаток.
    * `tests` - модульные тесты.
      * `test_tokenizer` - тесты для демонстации разработанной функциональности токенизатора.
      * `test_typos` - тесты для демонстации работы модуля исправления опечаток.
* `README.md` - описание.

## Подготовка окружения
Для корректной работы в директории `../assets/raw-dataset` должны располагаться два исходных датасета `train.csv` и `test.csv`.

## Токенизатор

Для запуска токенизатора следует убедиться, что в директории `raw-dataset` присутствуют файлы `test.csv` и `train.csv` и выполнить следующую команду из директории `tokenizer` проекта
```
python __main__.py
```
Результатом выполнения является набор набор аннотаций в формате tsv в соответствии со следующей структурой:
```
<sentence_2_token_N>    <sentence_2_stem_N> <sentence_2_lemma_N>
```
Для выполнения лабораторных работ был выбран датасет https://huggingface.co/datasets/ag_news
В директории /assets/annotated-corpus сформированы каталоги train и test, в которых будет размещаться набор файлов с расширением tsv, содержащие аннотации документов, составляющих исходный датасет. 
Каждому документу исходного датасета соответствует отдельный файл, в качестве названия файла используется идентификатор документа. Документы группируются по директориям в соответствии с их разбиением на классы, название класса используется в качестве названия соответствующей директории.

Пример содержимого сгенерированных файлов
```
Companies	compani	Companies
surrenders	surrend	surrender
High-Capacity	high-capac	High-Capacity
ESPN	espn	ESPN
associate	associ	associate
"Music Manifesto"
```
Токены, не являющиеся словами, такие как аббревиатуры, знаки пунктуации, числа, названия в кавычках не участвуют в дальнейшей нормализации и не передаются для стемминга и лемматизации.


Для лемматизации использовался WordNetLemmatizer. Как можно заметить, он успешно привёл слово 'surrenders' к 'surrender', но 'Companies' осталось неизменным. 
Для того, чтобы учесть такие ситуации, следует различать слова в начале предложения от именованных сущностей и приводить слова в начале предложения к строчным буквам. Однако корректное распознавание именованных сущностей и их дифференцирование от слов в начале предложения возможно лишь при учёте семантики и недостижимо при использовании токенизатора только на основе регулярных выражений.


## Исправление опечаток
Для генерации словаря следует выполнить следующую команду из директории `typos` проекта
```
python __main__.py
```
Далее для запуска модуля исправления опечаток следует убедиться, что в директории `raw-dataset` присутствует файл с опечатками `test-corrupted.csv` и выполнить запуск модуля исправления опечаток по алгоритму Хиршберга из директории `typos` проекта
```
python hirshberg.py
```
или по алгоритму, использующему поиск в окрестности префиксного дерева, построенного по словарю, из директории `typos` проекта
```
python tdict.py
```

## Запуск тестов

Для системы разработан набор модульных тестов, позволяющих оценить корректность работы программ. Для запуска тестов используется следующая команда, которую необходимо выполнять из корневой директории проекта:

```sh
PYTHONPATH=source python -m unittest
```

Система отображает стандартный отчет о результатах выполненя тестов:

```sh
...
----------------------------------------------------------------------
Ran 7 tests in 0.028s

OK

OK
```
